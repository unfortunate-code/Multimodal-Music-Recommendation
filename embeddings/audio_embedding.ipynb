{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIXzzB1ORwv2"
      },
      "source": [
        "## Audio Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fYPqpcjyNvxJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Phakawat\\miniconda3\\envs\\torch38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pickle\n",
        "\n",
        "class LinearVAE(nn.Module):\n",
        "    def __init__(self, latent_dim=150, beta=0):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = Encoder(latent_dim)\n",
        "        self.decoder = Decoder(latent_dim)\n",
        "        self.criterion = torch.nn.MSELoss()\n",
        "        self.beta = beta\n",
        "        \n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var) # standard deviation\n",
        "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
        "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
        "        return sample\n",
        " \n",
        "    def forward(self, x):\n",
        "        z, mu, log_var = self.encode(x) # encoding\n",
        "        reconstruction = self.decoder(z) # decoding\n",
        "        return reconstruction, mu, log_var\n",
        "    \n",
        "    def encode(self, x):\n",
        "        q = self.encoder(x)\n",
        "        q = q.reshape(-1, 2, self.latent_dim)\n",
        "        mu = q[:, 0, :] # the first feature values as mean\n",
        "        log_var = q[:, 1, :] # the other feature values as variance\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        return z, mu, log_var\n",
        "    \n",
        "    def loss(self, x, rec, mu, log_var):\n",
        "        # compute reconstruction loss\n",
        "        rec_loss = self.criterion(x, rec)\n",
        "        # compute KL divergence loss\n",
        "        log_sigma = 0.5*log_var\n",
        "        mu_unit = torch.zeros_like(mu)\n",
        "        log_sigma_unit = torch.zeros_like(log_sigma)\n",
        "        kl_loss = kl_divergence(mu, log_sigma, mu_unit, log_sigma_unit)\n",
        "        kl_loss = torch.sum(kl_loss,axis=1) # sum across the latent dimension, not the batch dimension\n",
        "        kl_loss = torch.mean(kl_loss) # make sure that this is a scalar, not a vector / array \n",
        "\n",
        "        return rec_loss + self.beta * kl_loss, {'rec_loss': rec_loss.cpu().detach().numpy(), 'kl_loss': kl_loss.cpu().detach().numpy()}\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim=150):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=11, out_features=100),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(in_features=100, out_features=100),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(in_features=100, out_features=latent_dim*2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x) \n",
        "    \n",
        " \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=150):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=latent_dim, out_features=100),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(in_features=100, out_features=100),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(in_features=100, out_features=11),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x) \n",
        "    \n",
        "def kl_divergence(mu1, log_sigma1, mu2, log_sigma2):\n",
        "  \"\"\"Computes KL[p||q] between two Gaussians defined by [mu, log_sigma].\"\"\"\n",
        "  return (log_sigma2 - log_sigma1) + (torch.exp(log_sigma1) ** 2 + (mu1 - mu2) ** 2) \\\n",
        "               / (2 * torch.exp(log_sigma2) ** 2) - 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LinearVAE(nn.Module):\n",
        "    def __init__(self, latent_dim=150, beta=0):\n",
        "        super(LinearVAE, self).__init__()\n",
        "        self.enc1 = nn.Linear(in_features=11, out_features=128)\n",
        "        self.enc2 = nn.Linear(in_features=128, out_features=latent_dim*2)\n",
        "        self.dec1 = nn.Linear(in_features=latent_dim, out_features=128)\n",
        "        self.dec2 = nn.Linear(in_features=128, out_features=11)\n",
        "        self.latent_dim = latent_dim\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var) # standard deviation\n",
        "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
        "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
        "        return sample\n",
        " \n",
        "    def forward(self, x, f=0):\n",
        "        # encoding\n",
        "        x = F.relu(self.enc1(x))\n",
        "        x = self.enc2(x).view(-1, 2, self.latent_dim)\n",
        "        # get `mu` and `log_var`\n",
        "        mu = x[:, 0, :] # the first feature values as mean\n",
        "        log_var = x[:, 1, :] # the other feature values as variance\n",
        "        # get the latent vector through reparameterization\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        if f == 1:\n",
        "            return z\n",
        "        # decoding\n",
        "        x = F.relu(self.dec1(z))\n",
        "        reconstruction = torch.sigmoid(self.dec2(x))\n",
        "        return reconstruction, mu, log_var\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H4qoB3mR5tV"
      },
      "source": [
        "### Train VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nVkovbIzNx1p"
      },
      "outputs": [],
      "source": [
        "feature_columns = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
        "    'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
        "\n",
        "def load_data(filepaths):\n",
        "    data = []\n",
        "    for filepath in filepaths:\n",
        "        print(f'loading {filepath}..')\n",
        "        # df = pd.read_csv('Data/audio/audio_features.txt',sep='\\t')\n",
        "        df = pd.read_csv(filepath,sep='\\t')\n",
        "        data.append(df)\n",
        "    data = pd.concat(data).drop_duplicates()\n",
        "    return data\n",
        "\n",
        "def preprocessing_features(data):    \n",
        "    feats = np.array(data[feature_columns],dtype=float)\n",
        "    # features = (features - np.mean(features, axis=0))/np.std(features, axis=0)\n",
        "    feats = (feats - np.min(feats, axis=0))/np.ptp(feats, axis=0)\n",
        "    print(feats.shape, feats.dtype)\n",
        "    return feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pRuleuBDR_Ak"
      },
      "outputs": [],
      "source": [
        "filepaths = ['Data/MPD_Large/audio_features.txt', 'Data/audio/audio_features2.txt', 'Data/audio/audio_features.txt']\n",
        "model_path = 'models/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0OuTPjHuOP96",
        "outputId": "5a6b07f0-0d46-45a0-cdf8-aee2dec9ccc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Data/MPD_Large/audio_features.txt..\n",
            "loading Data/audio/audio_features2.txt..\n",
            "loading Data/audio/audio_features.txt..\n",
            "(174506, 11) float64\n",
            "cuda:0\n",
            "Epoch 1/5\n",
            "It 0: Loss: 0.12385281920433044\n",
            "It 100: Loss: 0.01885204389691353\n",
            "It 200: Loss: 0.005638234317302704\n",
            "It 300: Loss: 0.0024627887178212404\n",
            "It 400: Loss: 0.001232040929608047\n",
            "It 500: Loss: 0.0008784806123003364\n",
            "It 600: Loss: 0.0008092426578514278\n",
            "It 700: Loss: 0.0006780403200536966\n",
            "It 800: Loss: 0.00069384032394737\n",
            "It 900: Loss: 0.0006690259324386716\n",
            "It 1000: Loss: 0.000546420575119555\n",
            "It 1100: Loss: 0.0004578487714752555\n",
            "It 1200: Loss: 0.0005179333966225386\n",
            "It 1300: Loss: 0.00042136709089390934\n",
            "It 1400: Loss: 0.000499481160659343\n",
            "It 1500: Loss: 0.0003966488875448704\n",
            "It 1600: Loss: 0.0003441406006459147\n",
            "It 1700: Loss: 0.0003909978549927473\n",
            "It 1800: Loss: 0.00034218071959912777\n",
            "It 1900: Loss: 0.0003415000974200666\n",
            "It 2000: Loss: 0.0003056724090129137\n",
            "It 2100: Loss: 0.00029725790955126286\n",
            "It 2200: Loss: 0.0002508910547476262\n",
            "It 2300: Loss: 0.0002556942345108837\n",
            "It 2400: Loss: 0.0003991005942225456\n",
            "It 2500: Loss: 0.00017761306662578136\n",
            "It 2600: Loss: 0.0001676746760495007\n",
            "It 2700: Loss: 0.00016627798322588205\n",
            "Epoch 2/5\n",
            "It 2800: Loss: 0.00014710918185301125\n",
            "It 2900: Loss: 0.00014859421935398132\n",
            "It 3000: Loss: 0.0001079536959878169\n",
            "It 3100: Loss: 0.0001572327018948272\n",
            "It 3200: Loss: 0.00013836100697517395\n",
            "It 3300: Loss: 0.0001220372214447707\n",
            "It 3400: Loss: 9.711311577120796e-05\n",
            "It 3500: Loss: 0.00012414748198352754\n",
            "It 3600: Loss: 9.475860133534297e-05\n",
            "It 3700: Loss: 0.0001219405239680782\n",
            "It 3800: Loss: 0.00010780150478240103\n",
            "It 3900: Loss: 8.471735054627061e-05\n",
            "It 4000: Loss: 0.00010947043483611196\n",
            "It 4100: Loss: 8.867093856679276e-05\n",
            "It 4200: Loss: 7.96016538515687e-05\n",
            "It 4300: Loss: 9.186781971948221e-05\n",
            "It 4400: Loss: 9.693840547697619e-05\n",
            "It 4500: Loss: 8.633911784272641e-05\n",
            "It 4600: Loss: 8.154215902322903e-05\n",
            "It 4700: Loss: 7.127012941055e-05\n",
            "It 4800: Loss: 8.350416464963928e-05\n",
            "It 4900: Loss: 7.569991430500522e-05\n",
            "It 5000: Loss: 6.061424210201949e-05\n",
            "It 5100: Loss: 7.036160241113976e-05\n",
            "It 5200: Loss: 7.024843216640875e-05\n",
            "It 5300: Loss: 6.58302815281786e-05\n",
            "It 5400: Loss: 7.07894578226842e-05\n",
            "Epoch 3/5\n",
            "It 5500: Loss: 7.852768612792715e-05\n",
            "It 5600: Loss: 7.04460107954219e-05\n",
            "It 5700: Loss: 7.526650733780116e-05\n",
            "It 5800: Loss: 8.178585267160088e-05\n",
            "It 5900: Loss: 5.5492895626230165e-05\n",
            "It 6000: Loss: 9.03034015209414e-05\n",
            "It 6100: Loss: 6.593024590983987e-05\n",
            "It 6200: Loss: 7.488365372410044e-05\n",
            "It 6300: Loss: 6.54435862088576e-05\n",
            "It 6400: Loss: 5.9111152950208634e-05\n",
            "It 6500: Loss: 5.079528273199685e-05\n",
            "It 6600: Loss: 6.926908827153966e-05\n",
            "It 6700: Loss: 6.361922714859247e-05\n",
            "It 6800: Loss: 6.870457582408562e-05\n",
            "It 6900: Loss: 6.739470700267702e-05\n",
            "It 7000: Loss: 6.209481216501445e-05\n",
            "It 7100: Loss: 5.1928691391367465e-05\n",
            "It 7200: Loss: 6.051043237675913e-05\n",
            "It 7300: Loss: 6.670222501270473e-05\n",
            "It 7400: Loss: 6.5554806496948e-05\n",
            "It 7500: Loss: 5.100234193378128e-05\n",
            "It 7600: Loss: 4.7575143980793655e-05\n",
            "It 7700: Loss: 5.2028914069524035e-05\n",
            "It 7800: Loss: 5.316390888765454e-05\n",
            "It 7900: Loss: 5.5110369430622086e-05\n",
            "It 8000: Loss: 4.896088285022415e-05\n",
            "It 8100: Loss: 5.510978735401295e-05\n",
            "Epoch 4/5\n",
            "It 8200: Loss: 5.557832264457829e-05\n",
            "It 8300: Loss: 6.74458933644928e-05\n",
            "It 8400: Loss: 5.043300916440785e-05\n",
            "It 8500: Loss: 4.9253238103119656e-05\n",
            "It 8600: Loss: 4.885194357484579e-05\n",
            "It 8700: Loss: 6.396856770152226e-05\n",
            "It 8800: Loss: 5.934333603363484e-05\n",
            "It 8900: Loss: 4.280772918718867e-05\n",
            "It 9000: Loss: 6.23193263891153e-05\n",
            "It 9100: Loss: 5.3701107390224934e-05\n",
            "It 9200: Loss: 7.743188325548545e-05\n",
            "It 9300: Loss: 5.02416369272396e-05\n",
            "It 9400: Loss: 4.364553024061024e-05\n",
            "It 9500: Loss: 4.138719305046834e-05\n",
            "It 9600: Loss: 5.699708708561957e-05\n",
            "It 9700: Loss: 5.4111336794449016e-05\n",
            "It 9800: Loss: 6.070888775866479e-05\n",
            "It 9900: Loss: 4.11321125284303e-05\n",
            "It 10000: Loss: 6.19434576947242e-05\n",
            "It 10100: Loss: 3.8901336665730923e-05\n",
            "It 10200: Loss: 5.841378151671961e-05\n",
            "It 10300: Loss: 6.57466662232764e-05\n",
            "It 10400: Loss: 4.338625876698643e-05\n",
            "It 10500: Loss: 4.566569987218827e-05\n",
            "It 10600: Loss: 4.007139432360418e-05\n",
            "It 10700: Loss: 4.2847390432143584e-05\n",
            "It 10800: Loss: 5.2784835133934394e-05\n",
            "It 10900: Loss: 4.90706370328553e-05\n",
            "Epoch 5/5\n",
            "It 11000: Loss: 4.2601637687766925e-05\n",
            "It 11100: Loss: 4.22147786593996e-05\n",
            "It 11200: Loss: 2.9874281608499587e-05\n",
            "It 11300: Loss: 5.368669008021243e-05\n",
            "It 11400: Loss: 3.21692532452289e-05\n",
            "It 11500: Loss: 4.4183350837556645e-05\n",
            "It 11600: Loss: 6.758300878573209e-05\n",
            "It 11700: Loss: 4.601186446961947e-05\n",
            "It 11800: Loss: 4.544690091279335e-05\n",
            "It 11900: Loss: 3.6247547541279346e-05\n",
            "It 12000: Loss: 4.0064784116111696e-05\n",
            "It 12100: Loss: 4.819650712306611e-05\n",
            "It 12200: Loss: 5.3202384151518345e-05\n",
            "It 12300: Loss: 3.7119127227924764e-05\n",
            "It 12400: Loss: 3.6770125007024035e-05\n",
            "It 12500: Loss: 3.5779521567747e-05\n",
            "It 12600: Loss: 5.089328624308109e-05\n",
            "It 12700: Loss: 3.7081885238876566e-05\n",
            "It 12800: Loss: 4.631535193766467e-05\n",
            "It 12900: Loss: 4.5422668335959315e-05\n",
            "It 13000: Loss: 3.872711749863811e-05\n",
            "It 13100: Loss: 3.137035309919156e-05\n",
            "It 13200: Loss: 3.8191472413018346e-05\n",
            "It 13300: Loss: 3.773010030272417e-05\n",
            "It 13400: Loss: 4.281591100152582e-05\n",
            "It 13500: Loss: 5.6379434681730345e-05\n",
            "It 13600: Loss: 5.4940021072980016e-05\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "feats_df = load_data(filepaths)\n",
        "feats = preprocessing_features(feats_df)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "batch_size = 64\n",
        "epoch = 5\n",
        "beta = 0.001\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(feats, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "model = LinearVAE(latent_dim=128, beta=beta).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(),lr=1e-3)          # create optimizer instance\n",
        "criterion = torch.nn.MSELoss()\n",
        "model.train()\n",
        "train_it = 0\n",
        "for ep in range(epoch):\n",
        "    print(f'Epoch {ep+1}/{epoch}')\n",
        "    for sample_img in data_loader:\n",
        "        # print(sample_img.float().shape)\n",
        "        opt.zero_grad()\n",
        "        # rec, mu, log_var = model.forward(sample_img.float().to(device))\n",
        "        # total_loss, losses = model.loss(sample_img.float().to(device), rec, mu, log_var)\n",
        "        # total_loss.backward()\n",
        "        # opt.step()\n",
        "        \n",
        "        # if train_it % 100 == 0:\n",
        "        #     print(\"It {}: Total Loss: {}, \\t Rec Loss: {},\\t KL Loss: {}\"\\\n",
        "        # .format(train_it, total_loss, losses['rec_loss'], losses['kl_loss']))\n",
        "        # train_it += 1\n",
        "        \n",
        "        opt.zero_grad()\n",
        "        reconstruction, mu, log_var = model.forward(sample_img.float().to(device))\n",
        "        loss = criterion(reconstruction, sample_img.float().to(device))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        if train_it % 100 == 0:\n",
        "            print(\"It {}: Loss: {}\".format(train_it, loss.item()))\n",
        "        train_it += 1\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YDjRVyqGQRzY"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), model_path+'/vae128org.p')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Data/MPD_Large//audio_features.txt..\n",
            "(70229, 11) float64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.62246964, 0.11411411, 0.72727273, ..., 0.16616617, 0.40423387,\n",
              "        0.42732022],\n",
              "       [0.39473684, 0.31031031, 0.45454545, ..., 0.37937938, 0.58870968,\n",
              "        0.74964421],\n",
              "       [0.5111336 , 0.25825826, 1.        , ..., 0.12012012, 0.64616935,\n",
              "        0.59545437],\n",
              "       ...,\n",
              "       [0.67307692, 0.83783784, 1.        , ..., 0.41941942, 0.57056452,\n",
              "        0.35915692],\n",
              "       [0.55060729, 0.86086086, 0.36363636, ..., 0.37637638, 0.16229839,\n",
              "        0.49420817],\n",
              "       [0.66396761, 0.11311311, 0.18181818, ..., 0.07717718, 0.31350806,\n",
              "        0.33188485]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_path = 'Data/MPD_Large/'\n",
        "feats_df = load_data([data_path + '/audio_features.txt'])\n",
        "feats = preprocessing_features(feats_df)\n",
        "feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "model = LinearVAE(latent_dim=128, beta=0.001).to(device)\n",
        "model.load_state_dict(torch.load(model_path+'/vae128org.p'))\n",
        "model.eval()\n",
        "# z, mu, log_var = model.encode(torch.Tensor(feats).to(device))\n",
        "# z = model.forward(torch.Tensor(feats).to(device), f=1)\n",
        "rec, mu, log_var = model.forward(torch.Tensor(feats).to(device), f=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([70229, 128])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mu.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pickle.dump(z.cpu().detach().numpy(), open(data_path + '/audio_embeddings.org.p','wb'))\n",
        "pickle.dump(mu.cpu().detach().numpy(), open(data_path + '/audio_embeddings_mean.org.p','wb'))\n",
        "# np.save(data_path + '/audio_embeddings.npy', z.cpu().detach().numpy())\n",
        "# np.save(data_path + '/audio_embeddings_mean.npy', mu.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([70229, 128]), torch.Size([70229, 128]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z.shape, mu.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by54wO_MSNYV"
      },
      "source": [
        "### Fine-tuning with genre classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "o7pIwVtXSMZ0"
      },
      "outputs": [],
      "source": [
        "from genre_utils import *\n",
        "\n",
        "data_path = 'data.txt'\n",
        "features_path = 'audio_features.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WpwFkop4Svgv"
      },
      "outputs": [],
      "source": [
        "class EncoderFC(nn.Module):\n",
        "    def __init__(self, latent_dim, n_class, encoder_weights=None, finetune=True):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = Encoder(latent_dim)\n",
        "        \n",
        "        if encoder_weights:\n",
        "            self.encoder.load_state_dict(encoder_weights)\n",
        "            \n",
        "        if finetune:\n",
        "            self.encoder.train()\n",
        "        else:\n",
        "            self.encoder.eval()\n",
        "            \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(latent_dim, 100),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(100, n_class)\n",
        "        )\n",
        "        self.sigm = nn.Sigmoid()\n",
        "    \n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var) # standard deviation\n",
        "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
        "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
        "        return sample\n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.reshape(-1, 2, self.latent_dim)\n",
        "        mu = x[:, 0, :] # the first feature values as mean\n",
        "        log_var = x[:, 1, :] # the other feature values as variance\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        return z\n",
        " \n",
        "    def forward(self, x):\n",
        "        # encoding\n",
        "        z = self.encode(x)\n",
        "        logits = self.classifier(z)\n",
        "        return self.sigm(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcvyKygzQvBm",
        "outputId": "cfb5f5f7-4d4d-49ed-ac27-f622b51155b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load data...\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "data = pd.read_csv(data_path,sep='\\t')\n",
        "assert 'spotify_id' in data.columns\n",
        "assert 'genre' in data.columns, 'need genre column where each song genre is in a|b|c|d format'\n",
        "data.spotify_id.astype(str)\n",
        "feats_df = pd.read_csv(features_path,sep='\\t')\n",
        "print(len(data),len(feats_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPTiVgfLT4dY",
        "outputId": "d6944c48-64a3-4251-cf83-69ec1a77d266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged length: 89156\n",
            "(89156, 11) float64\n",
            "{'unknown': 0, 'rock': 1, 'metal': 2, 'pop': 3, 'punk': 4, 'alternative': 5, 'post': 6, 'folk': 7, 'jazz': 8, 'rap': 9, 'electro': 10, 'soul': 11, 'melodic': 12, 'experimental': 13, 'death': 14, 'funk': 15, 'hop': 16, 'christian': 17, 'industrial': 18, 'indie': 19, 'hardcore': 20, 'house': 21, 'power': 22, 'noise': 23, 'new': 24, 'art': 25, 'progressive': 26, 'trap': 27, 'dance': 28, 'music': 29, 'hip': 30}\n",
            "(89156, 31)\n"
          ]
        }
      ],
      "source": [
        "# preprocess features, genres\n",
        "feats_df.id.astype(str)\n",
        "feats_df = feats_df[['id'] + feature_columns]\n",
        "feats_df = feats_df.rename(columns={'id':'spotify_id'})\n",
        "data = merge_df(data, feats_df)\n",
        "feats = preprocessing_features(data) \n",
        "# print(data)\n",
        "genres = get_genre_from_df(data, sep='|')\n",
        "genre_list = get_genre_list(genres)\n",
        "genre_onehot = create_multilabel_onehot(genres,genre_list)\n",
        "# print(len(genres),len(genre_list))\n",
        "# assert len(feats) == len(genre_onehot), f'{len(feats)} != {len(genre_onehot)}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3lNr6KUQXU3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "def calculate_metrics(pred, target, threshold=0.5):\n",
        "    pred = np.array(pred >= threshold, dtype=float)\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true=target, y_pred=pred)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD-DkksZT5-T",
        "outputId": "07373ec8-8394-4a20-eb50-6909727a6d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Load model...\n",
            "Epoch 1/5\n",
            "It 0: Loss: 0.7155431509017944\n",
            "It 1000: Loss: 0.15980269014835358\n",
            "0.31477410381802684\n",
            "Epoch 2/5\n",
            "It 2000: Loss: 0.13862667977809906\n",
            "0.3210215801516443\n",
            "Epoch 3/5\n",
            "It 3000: Loss: 0.1741984784603119\n",
            "It 4000: Loss: 0.129915252327919\n",
            "0.32249091480102293\n",
            "Epoch 4/5\n",
            "It 5000: Loss: 0.15029728412628174\n",
            "0.32201983040961907\n",
            "Epoch 5/5\n",
            "It 6000: Loss: 0.14682887494564056\n",
            "0.32360132800933195\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epoch = 5\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Load model\n",
        "# Load VAE encoder weights\n",
        "print('Load model...')\n",
        "model_vae = LinearVAE(latent_dim=150, beta=beta).to(device)\n",
        "model_vae.load_state_dict(torch.load(model_path+'/vae.p'))\n",
        "model_ft = EncoderFC(150, len(genre_list), model_vae.encoder.state_dict())\n",
        "model_ft.to(device)\n",
        "model_ft.train()\n",
        "\n",
        "data_loader_ft = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.Tensor(feats),torch.Tensor(genre_onehot)), batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "opt = torch.optim.Adam(model_ft.parameters(),lr=1e-3)          # create optimizer instance\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "train_it = 0\n",
        "results = []\n",
        "for ep in range(epoch):\n",
        "    print(f'Epoch {ep+1}/{epoch}')\n",
        "    preds = []\n",
        "    trues = []\n",
        "    for batch_x, batch_y in data_loader_ft:\n",
        "        opt.zero_grad()\n",
        "        output = model_ft.forward(batch_x.float().to(device))\n",
        "        rec_loss = criterion(output, batch_y.float().to(device))\n",
        "        rec_loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        preds.extend(output.cpu().detach().numpy())\n",
        "        trues.extend(batch_y.cpu().detach().numpy())\n",
        "        \n",
        "        if train_it % 1000 == 0:\n",
        "            print(\"It {}: Loss: {}\".format(train_it, rec_loss))\n",
        "        train_it += 1\n",
        "    \n",
        "    result = calculate_metrics(np.array(preds), np.array(trues))\n",
        "    print(result['accuracy'])\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "M4_Kgg5zT-5z"
      },
      "outputs": [],
      "source": [
        "torch.save(model_ft.state_dict(), model_path+'/audio_ft.p')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1S-m5qPUSiK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "audio_embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
